{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsHDLZ9f2sE6/12RmptADs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanya-mahajan/phish_url_detect/blob/master/ml_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OJs7xE6840bK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import os\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/malicious_phish.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "blD22YS06qah",
        "outputId": "50435767-672b-4c89-94f8-5923cb068e74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-81858a76fbf9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/malicious_phish.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/malicious_phish.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def has_ip(url):\n",
        "    match = re.search(\n",
        "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
        "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
        "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
        "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n",
        "    if match:\n",
        "\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "df['use_of_ip'] = df['url'].apply(lambda i: has_ip(i))\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def abnormal_url(url):\n",
        "    hostname = urlparse(url).hostname\n",
        "    hostname = str(hostname)\n",
        "    match = re.search(hostname, url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "df['abnormal_url'] = df['url'].apply(lambda i: abnormal_url(i))\n",
        "\n",
        "from googlesearch import search\n",
        "\n",
        "def google_index(url):\n",
        "    site = search(url, 5)\n",
        "    return 1 if site else 0\n",
        "df['google_index'] = df['url'].apply(lambda i: google_index(i))\n",
        "\n",
        "def count_dot(url):\n",
        "    count_dot = url.count('.')\n",
        "    return count_dot\n",
        "\n",
        "df['count.'] = df['url'].apply(lambda i: count_dot(i))\n",
        "\n",
        "def count_www(url):\n",
        "    url.count('www')\n",
        "    return url.count('www')\n",
        "\n",
        "df['count-www'] = df['url'].apply(lambda i: count_www(i))\n",
        "\n",
        "def count_atrate(url):\n",
        "\n",
        "    return url.count('@')\n",
        "\n",
        "df['count@'] = df['url'].apply(lambda i: count_atrate(i))\n",
        "\n",
        "\n",
        "def no_of_dir(url):\n",
        "    urldir = urlparse(url).path\n",
        "    return urldir.count('/')\n",
        "\n",
        "df['count_dir'] = df['url'].apply(lambda i: no_of_dir(i))\n",
        "\n",
        "def no_of_embed(url):\n",
        "    urldir = urlparse(url).path\n",
        "    return urldir.count('//')\n",
        "\n",
        "df['count_embed_domian'] = df['url'].apply(lambda i: no_of_embed(i))\n",
        "\n",
        "\n",
        "def shortening_service(url):\n",
        "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
        "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
        "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
        "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
        "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
        "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
        "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
        "                      'tr\\.im|link\\.zip\\.net',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['short_url'] = df['url'].apply(lambda i: shortening_service(i))\n",
        "\n",
        "def count_https(url):\n",
        "    return url.count('https')\n",
        "\n",
        "df['count-https'] = df['url'].apply(lambda i : count_https(i))\n",
        "\n",
        "def count_http(url):\n",
        "    return url.count('http')\n",
        "\n",
        "df['count-http'] = df['url'].apply(lambda i : count_http(i))\n",
        "\n",
        "def count_per(url):\n",
        "    return url.count('%')\n",
        "\n",
        "df['count%'] = df['url'].apply(lambda i : count_per(i))\n",
        "\n",
        "def count_ques(url):\n",
        "    return url.count('?')\n",
        "\n",
        "df['count?'] = df['url'].apply(lambda i: count_ques(i))\n",
        "\n",
        "def count_hyphen(url):\n",
        "    return url.count('-')\n",
        "\n",
        "df['count-'] = df['url'].apply(lambda i: count_hyphen(i))\n",
        "\n",
        "def count_equal(url):\n",
        "    return url.count('=')\n",
        "\n",
        "df['count='] = df['url'].apply(lambda i: count_equal(i))\n",
        "\n",
        "def url_length(url):\n",
        "    return len(str(url))\n",
        "\n",
        "\n",
        "df['url_length'] = df['url'].apply(lambda i: url_length(i))\n",
        "\n",
        "\n",
        "def hostname_length(url):\n",
        "    return len(urlparse(url).netloc)\n",
        "\n",
        "df['hostname_length'] = df['url'].apply(lambda i: hostname_length(i))\n",
        "\n",
        "df.head()\n",
        "\n",
        "def suspicious_words(url):\n",
        "    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "df['sus_url'] = df['url'].apply(lambda i: suspicious_words(i))\n",
        "\n",
        "\n",
        "def digit_count(url):\n",
        "    digits = 0\n",
        "    for i in url:\n",
        "        if i.isnumeric():\n",
        "            digits = digits + 1\n",
        "    return digits\n",
        "\n",
        "\n",
        "df['count-digits']= df['url'].apply(lambda i: digit_count(i))\n",
        "\n",
        "\n",
        "def letter_count(url):\n",
        "    letters = 0\n",
        "    for i in url:\n",
        "        if i.isalpha():\n",
        "            letters = letters + 1\n",
        "    return letters\n",
        "\n",
        "df['count-letters']= df['url'].apply(lambda i: letter_count(i))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#First Directory Length\n",
        "def fd_length(url):\n",
        "    urlpath= urlparse(url).path\n",
        "    try:\n",
        "        return len(urlpath.split('/')[1])\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "df['fd_length'] = df['url'].apply(lambda i: fd_length(i))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QM9uHPjH7h3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb_make = LabelEncoder()\n",
        "df[\"type_code\"] = lb_make.fit_transform(df[\"type\"])"
      ],
      "metadata": {
        "id": "jqC7odiQ-IGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictor Variables\n",
        "# filtering out google_index as it has only 1 value\n",
        "X = df[['use_of_ip','abnormal_url', 'count.', 'count-www', 'count@',\n",
        "       'count_dir', 'count_embed_domian', 'short_url', 'count-https',\n",
        "       'count-http', 'count%', 'count?', 'count-', 'count=', 'url_length',\n",
        "       'hostname_length', 'sus_url', 'fd_length',  'count-digits',\n",
        "       'count-letters']]\n",
        "\n",
        "#Target Variable\n",
        "y = df['type_code']"
      ],
      "metadata": {
        "id": "aNMKaXBIRcLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2,shuffle=True, random_state=5)"
      ],
      "metadata": {
        "id": "LfehSPCZSYTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100,max_features='sqrt')\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_rf,target_names=['benign', 'defacement','phishing','malware']))\n",
        "\n",
        "score = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "\n",
        "#XGboost\n",
        "xgb_c = xgb.XGBClassifier(n_estimators= 100)\n",
        "xgb_c.fit(X_train,y_train)\n",
        "y_pred_x = xgb_c.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_x,target_names=['benign', 'defacement','phishing','malware']))\n",
        "\n",
        "\n",
        "score = accuracy_score(y_test, y_pred_x)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "\n",
        "# Light GBM Classifier\n",
        "lgb = LGBMClassifier(objective='multiclass',boosting_type= 'gbdt',n_jobs = 5,\n",
        "          silent = True, random_state=5)\n",
        "LGB_C = lgb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_lgb = LGB_C.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_lgb,target_names=['benign', 'defacement','phishing','malware']))\n",
        "\n",
        "score = accuracy_score(y_test, y_pred_lgb)\n",
        "print(\"accuracy:   %0.3f\" % score)"
      ],
      "metadata": {
        "id": "Lb52LL_HSkVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
        "feat_importances.sort_values().plot(kind=\"barh\",figsize=(10, 6))"
      ],
      "metadata": {
        "id": "n0egAhfVW_sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#  individual models\n",
        "rf = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
        "xgb_c = xgb.XGBClassifier(n_estimators=100)\n",
        "lgb = LGBMClassifier(objective='multiclass', boosting_type='gbdt', n_jobs=5, silent=True, random_state=5)\n",
        "\n",
        "#list of models for the ensemble\n",
        "models = [('RandomForest', rf), ('XGBoost', xgb_c), ('LightGBM', lgb)]\n",
        "\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=models, voting='hard')\n",
        "\n",
        "# k-fold cv\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# evaluate each model separately\n",
        "\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    print(f'{name} Cross-Validation Accuracy: {cv_results.mean():.3f} +/- {cv_results.std():.3f}')\n",
        "\n",
        "# evaluate ensemble model\n",
        "ensemble_cv_results = cross_val_score(ensemble_model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "print(f'Ensemble Model Cross-Validation Accuracy: {ensemble_cv_results.mean():.3f} +/- {ensemble_cv_results.std():.3f}')\n",
        "\n",
        "# fit ensemble on training set\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on training set\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "\n",
        "# evaluate using test set\n",
        "print(\"Ensemble Model Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_ensemble, target_names=['benign', 'defacement', 'phishing', 'malware']))\n",
        "\n",
        "ensemble_score = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(\"Ensemble Model Accuracy:   %0.3f\" % ensemble_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "K9uz9A_bbxW_",
        "outputId": "3f1d2b65-db57-488b-8849-af9998f16f3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-914270006540>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} Cross-Validation Accuracy: {cv_results.mean():.3f} +/- {cv_results.std():.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(url):\n",
        "\n",
        "    status = []\n",
        "\n",
        "    status.append(has_ip(url))\n",
        "    status.append(abnormal_url(url))\n",
        "    status.append(count_dot(url))\n",
        "    status.append(count_www(url))\n",
        "    status.append(count_atrate(url))\n",
        "    status.append(no_of_dir(url))\n",
        "    status.append(no_of_embed(url))\n",
        "\n",
        "    status.append(shortening_service(url))\n",
        "    status.append(count_https(url))\n",
        "    status.append(count_http(url))\n",
        "\n",
        "    status.append(count_per(url))\n",
        "    status.append(count_ques(url))\n",
        "    status.append(count_hyphen(url))\n",
        "    status.append(count_equal(url))\n",
        "\n",
        "    status.append(url_length(url))\n",
        "    status.append(hostname_length(url))\n",
        "    status.append(suspicious_words(url))\n",
        "    status.append(digit_count(url))\n",
        "    status.append(letter_count(url))\n",
        "    status.append(fd_length(url))\n",
        "\n",
        "    return status\n",
        "\n",
        "# predict function\n",
        "def get_prediction_from_url(test_url):\n",
        "    features_test = main(test_url)\n",
        "    # Due to updates to scikit-learn, we now need a 2D array as a parameter to the predict function.\n",
        "    features_test = np.array(features_test).reshape((1, -1))\n",
        "    pred = lgb.predict(features_test)\n",
        "    if int(pred[0]) == 0:\n",
        "\n",
        "        res=\"SAFE\"\n",
        "        return res\n",
        "    elif int(pred[0]) == 1.0:\n",
        "\n",
        "        res=\"DEFACEMENT\"\n",
        "        return res\n",
        "    elif int(pred[0]) == 2.0:\n",
        "        res=\"PHISHING\"\n",
        "        return res\n",
        "\n",
        "    elif int(pred[0]) == 3.0:\n",
        "\n",
        "        res=\"MALWARE\"\n",
        "        return res\n",
        "\n",
        "\n",
        "# predicting sample\n",
        "\n",
        "urls = ['titaniumcorporate.co.za','en.wikipedia.org/wiki/North_Dakota']\n",
        "\n",
        "for url in urls:\n",
        "     print(get_prediction_from_url(url))"
      ],
      "metadata": {
        "id": "CVBiPa1gXInI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}